{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from pattern.en import sentiment\n",
    "from pattern.en import parse, split, wordnet\n",
    "from random import seed  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = ['what I am doing now text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "can't find SentiWordnet data file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bd329dad0f1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrelevant_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'JJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RB'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# adjectives, verbs, adverbs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlemmata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rohit\\Anaconda\\lib\\site-packages\\pattern\\text\\en\\wordnet\\__init__.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[0msentiwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rohit\\Anaconda\\lib\\site-packages\\pattern\\text\\en\\wordnet\\__init__.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    392\u001b[0m             glob.glob(os.path.join(MODULE, \"..\", self.path)))[0]\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"can't find SentiWordnet data file\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;31m# Map synset id: a-00193480\" => (193480, JJ).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;31m# Map synset id's to WordNet2 if VERSION == 2:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: can't find SentiWordnet data file"
     ]
    }
   ],
   "source": [
    "\n",
    "wordnet.sentiment.load()\n",
    "relevant_types = ['JJ', 'VB', 'RB'] # adjectives, verbs, adverbs\n",
    "score = 0\n",
    "sentences = split(parse(content, lemmata=True))\n",
    "for sentence in sentences:\n",
    "    for word in sentence.words:\n",
    "        if word.type in relevant_types:\n",
    "            pos, neg, obj = wordnet.sentiment[word.lemma]\n",
    "            score = score + ((pos - neg) * (1 - obj)) # weight subjective words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\n  NLTK was unable to find stanford-parser\\.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-parser\\.jar, see:\n    <http://nlp.stanford.edu/software/lex-parser.shtml>\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d61cc685383e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STANFORD_PARSER'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\Users\\rohit\\Documents\\stanford-corenlp-full-2015-12-09'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STANFORD_MODELS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\Users\\rohit\\Documents\\stanford-corenlp-full-2015-12-09'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstanford\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStanfordParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C:\\Users\\rohit\\Documents\\stanford-corenlp-full-2015-12-09\\stanford-corenlp-full-2015-12-09\\stanford-corenlp-3.6.0-models\\edu\\stanford\\nlp\\models\\lexparser\\englishPCFG.ser.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_parse_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hello, My name is Melroy.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"What is your name?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rohit\\Anaconda\\lib\\site-packages\\nltk\\parse\\stanford.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_to_jar, path_to_models_jar, model_path, encoding, verbose, java_options, corenlp_options)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_regex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             ),\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_JAR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         )\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rohit\\Anaconda\\lib\\site-packages\\nltk\\__init__.pyc\u001b[0m in \u001b[0;36mfind_jar_iter\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    656\u001b[0m \treturn [os.path.join(root, filename) \n\u001b[0;32m    657\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_jars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m \t\t\tfor filename in fnmatch.filter(filenames, '*.jar')]\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_decode_stdoutdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdoutdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\n  NLTK was unable to find stanford-parser\\.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-parser\\.jar, see:\n    <http://nlp.stanford.edu/software/lex-parser.shtml>\n==========================================================================="
     ]
    }
   ],
   "source": [
    "\n",
    "import os \n",
    "from nltk.parse import stanford \n",
    "os.environ['STANFORD_PARSER'] = 'C:\\Users\\rohit\\Documents\\stanford-corenlp-full-2015-12-09'\n",
    "os.environ['STANFORD_MODELS'] = 'C:\\Users\\rohit\\Documents\\stanford-corenlp-full-2015-12-09' \n",
    "parser = stanford.StanfordParser(model_path=\"C:\\Users\\rohit\\Documents\\stanford-corenlp-full-2015-12-09\\stanford-corenlp-full-2015-12-09\\stanford-corenlp-3.6.0-models\\edu\\stanford\\nlp\\models\\lexparser\\englishPCFG.ser.gz\")\n",
    "sentences = parser.raw_parse_sents((\"Hello, My name is Melroy.\", \"What is your name?\")) \n",
    "print sentences \n",
    "# GUI \n",
    "for line in sentences: \n",
    "    for sentence in line: \n",
    "        sentence.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3944444444444445"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial = TextBlob(\"this is sparta down risky.there are many\")\n",
    "testimonial.sentiment\n",
    "testimonial.sentiment.polarity\n",
    "testimonial.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "p=\"Violations may result substantial \"\"civil \"\"penalties, including treble damages. The federal False Claims Act also contains \\\"whistl\"\n",
    "p=p.replace(\"\\\"\",'')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(columns=('CIK','positivity','poscount','negativity','negcount','neutrality','neutcount','subjectivity','pattern_subjectivity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\Documents\\IPO Project\\riskfactors\n",
      "<open file '0000006885_riskfactors.txt', mode 'r' at 0x00000000201A0300>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-cb36c2a11c97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtext1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mdata1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0msentence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mneg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mneut\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/rohit/Documents/IPO Project/riskfactors\"\n",
    "os.chdir(path)\n",
    "dirs = os.listdir(path)\n",
    "z=0\n",
    "for file in dirs:\n",
    "    print os.getcwd()\n",
    "    with open (file, \"r\") as myfile:\n",
    "        print myfile\n",
    "        text1=myfile.read()\n",
    "        data1=text1.replace(\"\\\"\",\"\")\n",
    "        sentence=tokenize.sent_tokenize(data1)\n",
    "        neg=0\n",
    "        neut=0\n",
    "        pos=0\n",
    "        negcount=0\n",
    "        neutcount=0\n",
    "        poscount=0\n",
    "        subcount=0\n",
    "        pattern_subcount = 0\n",
    "        for i in range(0,len(sentence)):\n",
    "            sent = TextBlob(sentence[i])\n",
    "            pol=sent.sentiment.polarity\n",
    "            sub=sent.sentiment.subjectivity\n",
    "            if pol <= -0.2:\n",
    "                neg=pol+neg\n",
    "                negcount=negcount+1\n",
    "            if ((pol> -0.2) & (pol<0.2)):\n",
    "                neut=pol+neut\n",
    "                neutcount=neutcount+1\n",
    "            if pol >= 0.2:\n",
    "                pos=pol+pos\n",
    "                poscount=poscount+1\n",
    "            subcount=sub+subcount\n",
    "            \n",
    "            pattern_subcount= sentiment(sent)[1]+pattern_subcount\n",
    "            \n",
    "        totalneg= neg/negcount\n",
    "        totalneut=neut/neutcount\n",
    "        totalpos=pos/poscount\n",
    "        totalsub=subcount/(len(sentence))\n",
    "        totalpattern_sub=pattern_sub/(len(sentence))\n",
    "        print totalpos,poscount, totalneg,negcount, totalneut,neutcount\n",
    "        ##'positivity','poscount','negativity','negcount','neutrality','neutcount','subjectivity'\n",
    "        df=df.append({'CIK':file[:-4],'positivity':totalpos,'poscount':poscount,'negativity':totalneg,'negcount':negcount,'neutrality':totalneut,'neutcount':neutcount,'subjectivity':totalsub,'pattern_subjectivity':totalpattern_sub},ignore_index=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>positivity</th>\n",
       "      <th>poscount</th>\n",
       "      <th>negativity</th>\n",
       "      <th>negcount</th>\n",
       "      <th>neutrality</th>\n",
       "      <th>neutcount</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51548.txt</td>\n",
       "      <td>0.392818</td>\n",
       "      <td>382</td>\n",
       "      <td>-0.395004</td>\n",
       "      <td>0.392818</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>3543</td>\n",
       "      <td>0.178273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54003.txt</td>\n",
       "      <td>0.376702</td>\n",
       "      <td>453</td>\n",
       "      <td>-0.541776</td>\n",
       "      <td>0.376702</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>7061</td>\n",
       "      <td>0.140394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56679.txt</td>\n",
       "      <td>0.351610</td>\n",
       "      <td>182</td>\n",
       "      <td>-0.332264</td>\n",
       "      <td>0.351610</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.304592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70487.txt</td>\n",
       "      <td>0.339864</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.334277</td>\n",
       "      <td>0.339864</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>1049</td>\n",
       "      <td>0.296233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76174.txt</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>377</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2344</td>\n",
       "      <td>0.293327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>761745.txt</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>377</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2344</td>\n",
       "      <td>0.293327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51548</td>\n",
       "      <td>0.392818</td>\n",
       "      <td>382</td>\n",
       "      <td>-0.395004</td>\n",
       "      <td>0.392818</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>3543</td>\n",
       "      <td>0.178273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54003</td>\n",
       "      <td>0.376702</td>\n",
       "      <td>453</td>\n",
       "      <td>-0.541776</td>\n",
       "      <td>0.376702</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>7061</td>\n",
       "      <td>0.140394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56679</td>\n",
       "      <td>0.351610</td>\n",
       "      <td>182</td>\n",
       "      <td>-0.332264</td>\n",
       "      <td>0.351610</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.304592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70487</td>\n",
       "      <td>0.339864</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.334277</td>\n",
       "      <td>0.339864</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>1049</td>\n",
       "      <td>0.296233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>76174</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>377</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2344</td>\n",
       "      <td>0.293327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>761745</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>377</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2344</td>\n",
       "      <td>0.293327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51548</td>\n",
       "      <td>0.392818</td>\n",
       "      <td>382</td>\n",
       "      <td>-0.395004</td>\n",
       "      <td>-0.395004</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>3543</td>\n",
       "      <td>0.178273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>54003</td>\n",
       "      <td>0.376702</td>\n",
       "      <td>453</td>\n",
       "      <td>-0.541776</td>\n",
       "      <td>-0.541776</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>7061</td>\n",
       "      <td>0.140394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>56679</td>\n",
       "      <td>0.351610</td>\n",
       "      <td>182</td>\n",
       "      <td>-0.332264</td>\n",
       "      <td>-0.332264</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.304592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>70487</td>\n",
       "      <td>0.339864</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.334277</td>\n",
       "      <td>-0.334277</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>1049</td>\n",
       "      <td>0.296233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>76174</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>377</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2344</td>\n",
       "      <td>0.293327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>761745</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>377</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2344</td>\n",
       "      <td>0.293327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>51548</td>\n",
       "      <td>0.392818</td>\n",
       "      <td>382</td>\n",
       "      <td>-0.395004</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>3543</td>\n",
       "      <td>0.178273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>54003</td>\n",
       "      <td>0.376702</td>\n",
       "      <td>453</td>\n",
       "      <td>-0.541776</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>7061</td>\n",
       "      <td>0.140394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56679</td>\n",
       "      <td>0.351610</td>\n",
       "      <td>182</td>\n",
       "      <td>-0.332264</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.304592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>70487</td>\n",
       "      <td>0.339864</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.334277</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>1049</td>\n",
       "      <td>0.296233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>76174</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>377</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2344</td>\n",
       "      <td>0.293327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>761745</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>377</td>\n",
       "      <td>-0.315101</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2344</td>\n",
       "      <td>0.293327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CIK  positivity  poscount  negativity    negcount  neutrality  \\\n",
       "0    51548.txt    0.392818       382   -0.395004    0.392818    0.004390   \n",
       "1    54003.txt    0.376702       453   -0.541776    0.376702    0.008952   \n",
       "2    56679.txt    0.351610       182   -0.332264    0.351610    0.008097   \n",
       "3    70487.txt    0.339864       155   -0.334277    0.339864    0.008407   \n",
       "4    76174.txt    0.339601       377   -0.315101    0.339601    0.002361   \n",
       "5   761745.txt    0.339601       377   -0.315101    0.339601    0.002361   \n",
       "6        51548    0.392818       382   -0.395004    0.392818    0.004390   \n",
       "7        54003    0.376702       453   -0.541776    0.376702    0.008952   \n",
       "8        56679    0.351610       182   -0.332264    0.351610    0.008097   \n",
       "9        70487    0.339864       155   -0.334277    0.339864    0.008407   \n",
       "10       76174    0.339601       377   -0.315101    0.339601    0.002361   \n",
       "11      761745    0.339601       377   -0.315101    0.339601    0.002361   \n",
       "12       51548    0.392818       382   -0.395004   -0.395004    0.004390   \n",
       "13       54003    0.376702       453   -0.541776   -0.541776    0.008952   \n",
       "14       56679    0.351610       182   -0.332264   -0.332264    0.008097   \n",
       "15       70487    0.339864       155   -0.334277   -0.334277    0.008407   \n",
       "16       76174    0.339601       377   -0.315101   -0.315101    0.002361   \n",
       "17      761745    0.339601       377   -0.315101   -0.315101    0.002361   \n",
       "18       51548    0.392818       382   -0.395004  194.000000    0.004390   \n",
       "19       54003    0.376702       453   -0.541776  149.000000    0.008952   \n",
       "20       56679    0.351610       182   -0.332264   84.000000    0.008097   \n",
       "21       70487    0.339864       155   -0.334277   67.000000    0.008407   \n",
       "22       76174    0.339601       377   -0.315101  175.000000    0.002361   \n",
       "23      761745    0.339601       377   -0.315101  175.000000    0.002361   \n",
       "\n",
       "    neutcount  subjectivity  \n",
       "0        3543      0.178273  \n",
       "1        7061      0.140394  \n",
       "2        1291      0.304592  \n",
       "3        1049      0.296233  \n",
       "4        2344      0.293327  \n",
       "5        2344      0.293327  \n",
       "6        3543      0.178273  \n",
       "7        7061      0.140394  \n",
       "8        1291      0.304592  \n",
       "9        1049      0.296233  \n",
       "10       2344      0.293327  \n",
       "11       2344      0.293327  \n",
       "12       3543      0.178273  \n",
       "13       7061      0.140394  \n",
       "14       1291      0.304592  \n",
       "15       1049      0.296233  \n",
       "16       2344      0.293327  \n",
       "17       2344      0.293327  \n",
       "18       3543      0.178273  \n",
       "19       7061      0.140394  \n",
       "20       1291      0.304592  \n",
       "21       1049      0.296233  \n",
       "22       2344      0.293327  \n",
       "23       2344      0.293327  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['CIK'][z]=file\n",
    "        df['positivity'][z]=totalpos\n",
    "        df['poscount'][z]=poscount\n",
    "        df['negativity'][z]=totalneg\n",
    "        df['negcount'][z]=totalpos\n",
    "        df['neutrality'][z]=totalneut\n",
    "        df['neutcount'][z]=neutcount\n",
    "        df['subjectivity'][z]=totalsub\n",
    "        z=z+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46153846153846156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('this is not very good')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.26923076923076916, 0.46153846153846156)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
